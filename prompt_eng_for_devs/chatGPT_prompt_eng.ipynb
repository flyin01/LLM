{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ChatGPT Prompt Engineering for Developers.  \n",
        "  \n",
        "...\n",
        "  \n",
        "**Content**\n",
        "1. [Introduction(https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/1/introduction)\n",
        "2. Guidelines for Prompting"
      ],
      "metadata": {
        "id": "b4Mcg3Ji7wg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Guidelines for Prompting"
      ],
      "metadata": {
        "id": "igjIDVEo8Nlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Aa2SFno9JnM",
        "outputId": "42bef3ba-2bff-4a18-c256-c7ee9263ed48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/328.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m327.7/328.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rPicYQjP7qZv"
      },
      "outputs": [],
      "source": [
        "# import libraries and set api key\n",
        "\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = \"sk-\" # Replace ... with your key and set as os variable\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkRfQekB-uiE",
        "outputId": "421d4659-f01c-4d5e-d9a3-b15c1992460a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.35.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create helper function to use propmpts and observer the generated output.\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "dQKR6fER-eG9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Prompting Principles**  \n",
        "Principle 1: Write clear and specific instructions    \n",
        "Principle 2: Give the model time to \"think\"  \n",
        "  \n",
        "####**Princple 1: Write clear and specific instructions**  \n",
        "\n",
        "####**Tactics**  \n",
        "**Tactic 1:** Use delimiters to indicate clearly distinct parts of input. Delimiters can be e.g ''', <<<>>>, `<tag> </tag>`, :."
      ],
      "metadata": {
        "id": "i41b6flo-6cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\\n",
        "providing instructions that are as clear and \\\n",
        "specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, \\\n",
        "and reduce the chances of receiving irrelevant \\\n",
        "or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. \\\n",
        "In many cases, longer prompts provide more clarity \\\n",
        "and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgHRfwYm_jF9",
        "outputId": "18f08d1b-338e-4ce8-b102-5bf15018f547"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Providing clear and specific instructions to a model will guide it towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, with longer prompts often providing more clarity and context for more detailed and relevant outputs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tactic 2:** Ask for structured output.  \n",
        "E.g JSON, HTML."
      ],
      "metadata": {
        "id": "TyKL0twHBh7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up movie titles along \\\n",
        "with their directors and genres.\n",
        "Provide them in JSON format with the following keys:\n",
        "movie_id, title, director, genre.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbTlXSjPBsqw",
        "outputId": "696f3234-e562-4bcb-be82-f40f309ce382"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"movie_id\": 1,\n",
            "        \"title\": \"Galactic Odyssey\",\n",
            "        \"director\": \"Aurora Steele\",\n",
            "        \"genre\": \"Sci-Fi\"\n",
            "    },\n",
            "    {\n",
            "        \"movie_id\": 2,\n",
            "        \"title\": \"Midnight Masquerade\",\n",
            "        \"director\": \"Julian Black\",\n",
            "        \"genre\": \"Romance\"\n",
            "    },\n",
            "    {\n",
            "        \"movie_id\": 3,\n",
            "        \"title\": \"Shadow Realm\",\n",
            "        \"director\": \"Elena Nightshade\",\n",
            "        \"genre\": \"Horror\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A15_ySfzC9t2",
        "outputId": "e003f814-6aeb-42c9-8f73-fa91ce9bd314"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the response string as a list of dicts\n",
        "import json\n",
        "movies: list = json.loads(response)\n",
        "print(type(movies))\n",
        "print(json.dumps(movies, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehtD7RuBChPu",
        "outputId": "15f43b9d-3eb0-4446-cd04-65445c5c4f31"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "[\n",
            "  {\n",
            "    \"movie_id\": 1,\n",
            "    \"title\": \"Galactic Odyssey\",\n",
            "    \"director\": \"Aurora Steele\",\n",
            "    \"genre\": \"Sci-Fi\"\n",
            "  },\n",
            "  {\n",
            "    \"movie_id\": 2,\n",
            "    \"title\": \"Midnight Masquerade\",\n",
            "    \"director\": \"Julian Black\",\n",
            "    \"genre\": \"Romance\"\n",
            "  },\n",
            "  {\n",
            "    \"movie_id\": 3,\n",
            "    \"title\": \"Shadow Realm\",\n",
            "    \"director\": \"Elena Nightshade\",\n",
            "    \"genre\": \"Horror\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tactis 3:** Ask model to check if conditions are satisfied"
      ],
      "metadata": {
        "id": "MuckwuhFDvlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some \\\n",
        "water boiling. While that's happening, \\\n",
        "grab a cup and put a tea bag in it. Once the water is \\\n",
        "hot enough, just pour it over the tea bag. \\\n",
        "Let it sit for a bit so the tea can steep. After a \\\n",
        "few minutes, take out the tea bag. If you \\\n",
        "like, you can add some sugar or milk to taste. \\\n",
        "And that's it! You've got yourself a delicious \\\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - ...\n",
        "…\n",
        "Step N - ...\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNwJEfwXD1Mm",
        "outputId": "cdf08556-83b1-421f-ace7-2f8e4462dd95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Once the water is hot enough, pour it over the tea bag.\n",
            "Step 4 - Let it sit for a bit so the tea can steep.\n",
            "Step 5 - After a few minutes, take out the tea bag.\n",
            "Step 6 - Add some sugar or milk to taste.\n",
            "Step 7 - Enjoy your delicious cup of tea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are \\\n",
        "singing. It's a beautiful day to go for a \\\n",
        "walk in the park. The flowers are blooming, and the \\\n",
        "trees are swaying gently in the breeze. People \\\n",
        "are out and about, enjoying the lovely weather. \\\n",
        "Some are having picnics, while others are playing \\\n",
        "games or simply relaxing on the grass. It's a \\\n",
        "perfect day to spend time outdoors and appreciate the \\\n",
        "beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6BWqHwtFFyX",
        "outputId": "93c10532-addc-4ab7-bcd2-8073d7978a86"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tactic 4:** Few-shot prompting"
      ],
      "metadata": {
        "id": "wnFgO__9Fgo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "\n",
        "<grandparent>: The river that carves the deepest \\\n",
        "valley flows from a modest spring; the \\\n",
        "grandest symphony originates from a single note; \\\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2aa1ZctFYRw",
        "outputId": "f6eb80f1-9542-4837-f304-cd42ba82d726"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<grandparent>: The tallest trees weather the strongest storms; the brightest stars shine in the darkest nights; the strongest hearts are forged in the hottest fires.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Princple 2: Give the model time to think**  \n",
        "####**Tactics**  \n",
        "\n",
        "**Tactic 1:** Specify the steps required to complete the task  "
      ],
      "metadata": {
        "id": "_5Sdah6BGHEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "In a charming village, siblings Jack and Jill set out on\\\n",
        " a quest to fetch water from a hilltop \\\n",
        "well. As they climbed, singing joyfully, misfortune \\\n",
        "struck—Jack tripped on a stone and tumbled \\\n",
        "down the hill, with Jill following suit. \\\n",
        "Though slightly battered, the pair returned home to \\\n",
        "comforting embraces. Despite the mishap, \\\n",
        "their adventurous spirits remained undimmed, and they \\\n",
        "continued exploring with delight.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExNp8FhXGZKw",
        "outputId": "a7a08111-c456-49cd-b555-b2bd6b2590c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 - Jack and Jill go on a quest to fetch water from a well, but encounter misfortune on the way back home.\n",
            "\n",
            "2 - Jack et Jill partent en quête d'eau d'un puits, mais rencontrent un malheur sur le chemin du retour.\n",
            "\n",
            "3 - Jack, Jill\n",
            "\n",
            "4 - {\n",
            "    \"summary\": \"Jack and Jill go on a quest to fetch water from a well, but encounter misfortune on the way back home.\",\n",
            "    \"names\": [\"Jack\", \"Jill\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask for output in a specified format."
      ],
      "metadata": {
        "id": "OtBrYTD7Htzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary>\n",
        "Translation: <summary translation>\n",
        "Names: <list of names in summary>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text: <{text}>\n",
        "\"\"\"\n",
        "response = get_completion(prompt_2)\n",
        "print(\"\\nCompletion for prompt 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZIZch1xHx5a",
        "outputId": "4da6586b-54d2-4860-ff74-49b71aaaed0b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Completion for prompt 2:\n",
            "Summary: Jack and Jill, two siblings, go on a quest to fetch water from a well on a hill, but encounter misfortune along the way.\n",
            "\n",
            "Translation: Jack et Jill, deux frères et sœurs, partent en quête d'eau d'un puits sur une colline, mais rencontrent des malheurs en chemin.\n",
            "\n",
            "Names: Jack, Jill\n",
            "\n",
            "Output JSON: \n",
            "{\n",
            "  \"french_summary\": \"Jack et Jill, deux frères et sœurs, partent en quête d'eau d'un puits sur une colline, mais rencontrent des malheurs en chemin.\",\n",
            "  \"num_names\": 2\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}