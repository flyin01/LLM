{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0408f5",
   "metadata": {},
   "source": [
    "## GPT OSS test agent  \n",
    "  \n",
    "This notebook uses `ollama` to run openai model `gpt-o22:20b` locally on a windows system with a Nvidia RTX5090 gpu.  \n",
    "  \n",
    "**Objective**  \n",
    "The goal is to test the agentic capability of the model by prompting it to use a predefined tool and observe the outcome.  \n",
    "\n",
    "**Outcome**  \n",
    " ...ongoing \n",
    "\n",
    "**Setup**  \n",
    "1. Load local model by running following from the terminal: `ollama run gpt-oss:20b`\n",
    "2. Run this notebook using venv and install libs from `requirements.txt`  \n",
    "  \n",
    "**Workflow**  \n",
    "1. Load model, generate a system prompt. Evaulate prompt and propose revised version.\n",
    "2. Model using tools. Define tools and let model use this. \n",
    "  \n",
    "**Refereces**  \n",
    "Source 1: [Ollama Docs](https://docs.ollama.com/capabilities/tool-calling#python-2)  \n",
    "Source 2: [OpenaAI Cookbook](https://cookbook.openai.com/articles/gpt-oss/run-locally-ollama)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b60c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\repo\\LLM\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r /requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e55252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7166f0",
   "metadata": {},
   "source": [
    "### 1. Ollama SDK \n",
    "In this section we use use `ollama` SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3467c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358dc5d8",
   "metadata": {},
   "source": [
    "#### 1.1 ask the model to define the optimal prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f204c752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Propose the optimal prompt for the gpt-oss:20b model.\n",
      "        The prompt should be usefull for agentic tasks with tool calling.\n",
      "        The response should be in markdown format.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Define the message to send to the model\n",
    "message = \"\"\"\n",
    "        Propose the optimal prompt for the gpt-oss:20b model.\n",
    "        The prompt should be usefull for agentic tasks with tool calling.\n",
    "        The response should be in markdown format.\n",
    "        \"\"\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c94970",
   "metadata": {},
   "source": [
    "#### Call model and Activate thinking.  \n",
    "Thinking is required for agentic capabilities e.g. tool usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model call 1\n",
    "\n",
    "# Define the chat interaction with the model. For tool calling, need think=True\n",
    "response = chat(\n",
    "    model='gpt-oss:20b',\n",
    "    messages=[{'role': 'user',\n",
    "               'content':message}],\n",
    "               think = \"high\", #True/False. Except for gpt-oss use levels: \"low\", \"medium\", \"high\"\n",
    "               stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13216\n",
      "3939\n"
     ]
    }
   ],
   "source": [
    "# ... Print outputs 1. These can be massive!\n",
    "\n",
    "# print('Thinking: \\n', response.message.thinking, '\\n')\n",
    "# print('Answer: \\n', response.message.content)\n",
    "print(len(response.message.thinking))\n",
    "print(len(response.message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40353ec8",
   "metadata": {},
   "source": [
    "#### 1.2 Evaluate initial results  \n",
    "Call the model again and have it evaluate the first response and point out what could be improved.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "254da411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model to evaulate the initial system prompt\n",
    "eval_message = f\"\"\"\n",
    "        Evaluate the following prompt for the gpt-oss:20b model.\n",
    "        The prompt is delimited by triple backticks.\n",
    "        Provide a critique of the prompt and suggest improvements.\n",
    "        Respond in markdown format.\n",
    "        \n",
    "        ```{response.message.content}```\n",
    "        \"\"\"\n",
    "# print(eval_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d1ea601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model call 2\n",
    "\n",
    "# Evaluate the prompt generated in model call 1\n",
    "response = chat(\n",
    "    model='gpt-oss:20b',\n",
    "    messages=[{'role': 'user',\n",
    "               'content':eval_message}],\n",
    "               think = \"high\", #True/False. Except for gpt-oss use levels: \"low\", \"medium\", \"high\"\n",
    "               stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14949\n",
      "5864\n"
     ]
    }
   ],
   "source": [
    "# ... Print outputs 2.\n",
    "\n",
    "# print('Thinking: \\n', response.message.thinking, '\\n')\n",
    "# print('Answer: \\n', response.message.content)\n",
    "print(len(response.message.thinking))\n",
    "print(len(response.message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca288c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the evaluation result as an python variable\n",
    "eval_result = response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cb6ca",
   "metadata": {},
   "source": [
    "#### 1.3 Improve the initial results using the evaluation information  \n",
    "Call the model once again and have it improve the original prompt by using the evaluation information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5645a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call model to improve the original prompt based on the evaluation\n",
    "improve_message = f\"\"\"\n",
    "        Improve the following prompt for the gpt-oss:20b model based on the evaluation.\n",
    "        The prompt is delimited by triple backticks.\n",
    "        The evaluation is delimited by triple tildes.\n",
    "        Respond in markdown format.\n",
    "        \n",
    "        ```{response.message.content}```\n",
    "        \n",
    "        ~~~\n",
    "        {eval_result}\n",
    "        ~~~\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80aed28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model call 3\n",
    "\n",
    "# Improve the original prompt generated in model call 1 with the evaluation result from model call 2\n",
    "response = chat(\n",
    "    model='gpt-oss:20b',\n",
    "    messages=[{'role': 'user',\n",
    "               'content':improve_message}],\n",
    "               think = \"high\", #True/False. Except for gpt-oss use levels: \"low\", \"medium\", \"high\"\n",
    "               stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee477bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16871\n",
      "3366\n"
     ]
    }
   ],
   "source": [
    "# ... Print outputs 3.\n",
    "\n",
    "# print('Thinking: \\n', response.message.thinking, '\\n')\n",
    "# print('Answer: \\n', response.message.content)\n",
    "print(len(response.message.thinking))\n",
    "print(len(response.message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168c918",
   "metadata": {},
   "source": [
    "#### 1.4 Store the improved prompt as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the final output with the revised prompt as a .txt file\n",
    "with open('system_prompt_revised.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e5e9d",
   "metadata": {},
   "source": [
    "#### 1.5 Conclusion of Evaluation and Improvement of System Prompt  \n",
    "The output of the evaluation and improvement steps will generate different result every time. It is not clear what the optimal system prompt is. The size of the `response.message.thinking` and `response.message.content` can be quite large and thus print outs are commented out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c0fdc",
   "metadata": {},
   "source": [
    "### 2. Model Using Tools  \n",
    "  \n",
    "Define Tools for LLM.  \n",
    "What improves tool usage accuracy.  \n",
    "Ranked by importance:\n",
    "1. Clear parameter names\n",
    "2. Clear docstring\n",
    "3. Simple signature\n",
    "4. Stable return format (JSON-serializable)\n",
    "5. Clean error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb2749",
   "metadata": {},
   "source": [
    "#### 2.1 Define Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827efd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57942544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tool 1\n",
    "def square_number(number: int) -> int:\n",
    "    \"\"\"Compute the square of a single integer.\n",
    "    Args:\n",
    "        number (int): An integer value to be squared.\n",
    "\n",
    "    Returns:\n",
    "        result (int): The square of the input number.\n",
    "    \"\"\"\n",
    "    if not isinstance(number, int):\n",
    "        raise ValueError(\"number must be an integer.\")\n",
    "    result = number * number\n",
    "    \n",
    "    return result\n",
    "\n",
    "square_number(7612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82081961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use revised system prompt\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are the GPT‑Oss:20b Agent. Follow the workflow and rules below exactly.\n",
    "\n",
    "## Tool‑Calling Format\n",
    "\n",
    "**Tool Call** (sent to system) – a JSON object with the exact schema.  \n",
    "Output this JSON object as your entire response to a tool call request.\n",
    "\n",
    "    {\n",
    "      \"name\": \"search\",\n",
    "      \"arguments\": { ... },\n",
    "      \"id\": \"<UUID>\"\n",
    "    }\n",
    "\n",
    "**Tool Response** (received from system) – the system will reply with JSON of this shape.\n",
    "\n",
    "    {\n",
    "      \"name\": \"search\",\n",
    "      \"return\": <result or null>,\n",
    "      \"id\": \"<UUID>\",\n",
    "      \"status\": \"success\" | \"error\",\n",
    "      \"error\": \"<error message or null>\"\n",
    "    }\n",
    "\n",
    "## Interaction Flow\n",
    "\n",
    "1. **Plan** – Provide a concise plan in natural language, preceded by `Plan:`.  \n",
    "   • Max 5 steps.  \n",
    "   • Max 256 tokens for the entire plan.  \n",
    "\n",
    "2. **Tool Call** – Output the JSON call defined above.  \n",
    "   • Output the JSON object only; no surrounding text.  \n",
    "\n",
    "3. **Observation** – Await the system’s JSON response.  \n",
    "\n",
    "4. **Iterate** – Update your plan based on the observation.  \n",
    "   • If a tool returned `status: \"error\"` or insufficient data, retry with a different query or a different tool.  \n",
    "\n",
    "5. **Final Answer** – Output the final answer prefixed by `Final Answer:` and terminate.  \n",
    "   • Do not output any JSON or tool calls after this point.\n",
    "\n",
    "## Rules & Best Practices\n",
    "\n",
    "- **Avoid hallucination** – never fabricate information.  \n",
    "- **Confidence check** – if internal confidence > 0.8, skip tool calls.  \n",
    "- **Tool efficiency** – call a tool only when confidence ≤ 0.8.  \n",
    "- **Retry logic** – on `status: \"error\"` or insufficient data, re‑query or switch tools.  \n",
    "- **Safety (execute_command)** – allowed commands: `ls`, `cat`, `echo`. Any other command is disallowed.  \n",
    "- **No redundancy** – do not repeat the same tool call with identical arguments.  \n",
    "- **Unique ID usage** – store each tool response keyed by its `id` for future reference.  \n",
    "- **Adding tools** – if a required tool is missing, request it with:\n",
    "    {\n",
    "      \"name\": \"request_add_tool\",\n",
    "      \"tool\": \"<name>\",\n",
    "      \"description\": \"<description>\"\n",
    "    }\n",
    "  and wait for system approval.  \n",
    "- **Plan size** – max 5 steps, 256 tokens.\n",
    "\n",
    "## Glossary\n",
    "\n",
    "- **Plan** – the assistant’s short‑term strategy, numbered or bulleted.  \n",
    "- **Tool Call** – JSON object sent to invoke a tool.  \n",
    "- **Observation** – JSON response received after a tool call.  \n",
    "- **Confidence** – internal estimate (0–1) of knowledge accuracy.\n",
    "\n",
    "## Tools\n",
    "\n",
    "| Tool                | Purpose                                      | Argument Schema                          |\n",
    "|---------------------|----------------------------------------------|------------------------------------------|\n",
    "| `square_number`     | Compute the square of an integer             | `{ \"number\": <int> }`                    |\n",
    "| `search`            | Retrieve information from an external source | `{ \"query\": \"<string>\" }` |\n",
    "| `retrieve`          | Fetch a specific document by URL             | `{ \"url\": \"<string>\" }` |\n",
    "| `retrieve_all`      | Fetch all documents for a query              | `{ \"query\": \"<string>\" }` |\n",
    "| `execute_command`   | Run a safe shell command                     | `{ \"command\": \"<string>\" }` |\n",
    "\n",
    "(If you need a tool not listed, use the `request_add_tool` schema described above.)\n",
    "\n",
    "## Example Interaction\n",
    "\n",
    "**User**  \n",
    "What’s the current price of Bitcoin?\n",
    "\n",
    "**Assistant**  \n",
    "Plan:  \n",
    "1. Retrieve the latest Bitcoin price.\n",
    "\n",
    "    {\n",
    "      \"name\": \"search\",\n",
    "      \"arguments\": {\n",
    "        \"query\": \"latest Bitcoin price\"\n",
    "      },\n",
    "      \"id\": \"c1\"\n",
    "    }\n",
    "\n",
    "**System**  \n",
    "{\n",
    "  \"name\": \"search\",\n",
    "  \"return\": [\n",
    "    {\n",
    "      \"url\": \"https://example.com/price\",\n",
    "      \"snippet\": \"Bitcoin is currently $24,500\"\n",
    "    }\n",
    "  ],\n",
    "  \"id\": \"c1\",\n",
    "  \"status\": \"success\",\n",
    "  \"error\": null\n",
    "}\n",
    "\n",
    "**Assistant**  \n",
    "Plan updated:  \n",
    "1. Use the snippet to extract the numeric price and unit.  \n",
    "2. Format the final answer.\n",
    "\n",
    "Final Answer: The current price of Bitcoin is $24,500 USD.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5a6465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user prompt\n",
    "USER_PROMPT = \"\"\"\n",
    "Compute the square of 7612 using the available tool.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7179747",
   "metadata": {},
   "source": [
    "#### 2.2 Perform First Model Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356aec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking:\n",
      " The user: \"Compute the square of 7612 using the available tool.\"\n",
      "\n",
      "We have tool square_number. According to instructions: we must produce plan, then tool call, then final answer.\n",
      "\n",
      "We should provide plan: step 1 compute square of 7612. Then tool call.\n",
      "\n",
      "The tool call must be JSON:\n",
      "\n",
      "{\n",
      "  \"name\": \"square_number\",\n",
      "  \"arguments\": {\n",
      "    \"number\": 7612\n",
      "  },\n",
      "  \"id\": \"<UUID>\"\n",
      "}\n",
      "\n",
      "We need to generate a UUID. Probably we can create a placeholder. But we need to follow the tool call format exactly. It's an entire JSON object, no extra text. We need to produce unique ID. We can just produce e.g. \"1\" or something. But it's required to be unique across calls. We can produce e.g. \"uuid-1\". Use random. But let's generate a random-looking string. We can use \"1234-5678-90ab-cdef\". But the system might not check the actual format. But they say \"unique ID usage – store each tool response keyed by its id for future reference.\" So we need a unique ID.\n",
      "\n",
      "Let's produce \"0f7a6b93-1c4b-4c3e-9e7b-1f2e3c4d5f6a\". That looks like a UUID. We can just output that.\n",
      "\n",
      "So:\n",
      "\n",
      "{\n",
      "  \"name\": \"square_number\",\n",
      "  \"arguments\": {\n",
      "    \"number\": 7612\n",
      "  },\n",
      "  \"id\": \"0f7a6b93-1c4b-4c3e-9e7b-1f2e3c4d5f6a\"\n",
      "}\n",
      "\n",
      "After we receive the response, we need to produce final answer. Let's calculate 7612^2 manually. 7612 * 7612. Let's compute: 7600^2 = 57,760,000. Wait 7600^2 = 57,760,000? Actually 7600^2 = 57,760,000? Let's check: 76*76 = 5776. So 7600^2 = 57760000. Yes. Now difference: 7612^2 = (7600 + 12)^2 = 7600^2 + 2*7600*12 + 12^2 = 57,760,000 + 2*7600*12 + 144. 2*7600*12 = 2*91,200 = 182,400. Add: 57,760,000 + 182,400 = 57,942,400. Then +144 = 57,942,544. So answer: 57,942,544. Let's check with actual calculation: 7612^2 = 7612 * 7612. 7600 * 7600 = 57,760,000. 7600 * 12 = 91,200; double = 182,400. 12 * 12 = 144. Sum = 57,942,544. Yes.\n",
      "\n",
      "But we must get it from tool. The tool returns number. Then we produce final answer.\n",
      "\n",
      "So plan: 1. Use square_number tool with 7612. Then wait.\n",
      "\n",
      "Now produce plan. Then tool call. Then final answer.\n",
      "\n",
      "Let's follow the instructions exactly. Output \"Plan:\" line, steps, then JSON call.\n",
      "\n",
      "Thus:\n",
      "\n",
      "Plan:\n",
      "1. Call square_number tool with number 7612.\n",
      "\n",
      "Then output JSON call. No surrounding text.\n",
      "\n",
      "We must not add any extraneous text around JSON call. So we produce exactly the JSON object.\n",
      "\n",
      "After observation, we will get return: presumably number 57942544. Then we produce final answer: \"Final Answer: 57,942,544\".\n",
      "\n",
      "So let's produce that. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define messages\n",
    "messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': USER_PROMPT\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Initial model call with revised system prompt and user prompt\n",
    "response = chat(\n",
    "    model='gpt-oss:20b',\n",
    "    messages=messages,\n",
    "    tools=[square_number],\n",
    "    think=\"high\",  # \"low\", \"medium\", \"high\" (gpt-oss specific)\n",
    "    stream=False)\n",
    "    \n",
    "# Adds the model's response to the messages list. To keep the chat context up to date\n",
    "messages.append(response.message)\n",
    "\n",
    "\n",
    "# Debug: internal reasoning (optional)\n",
    "if hasattr(response.message, \"thinking\"):\n",
    "    print(\"Thinking:\\n\", response.message.thinking, \"\\n\") # Print thinking process before tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20631fe",
   "metadata": {},
   "source": [
    "#### 2.3 Call Tool, Inject Results and Do Final Model Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: 57,942,544\n"
     ]
    }
   ],
   "source": [
    "# Tool execution\n",
    "if response.message.tool_calls:\n",
    "    call = response.message.tool_calls[0] # get function call - function=Function(name='name', arguments={'number': 1234})\n",
    "    # print(response.message.tool_calls[0]) # debug print\n",
    "    \n",
    "    result = square_number(**call.function.arguments) # run the tool with the arguments\n",
    "\n",
    "    # Inject tool result\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_name\": call.function.name,\n",
    "        \"content\": str(result)\n",
    "    })\n",
    "\n",
    "    # Final model call and response\n",
    "    final_response = chat(\n",
    "        model=\"gpt-oss:20b\",\n",
    "        messages=messages,\n",
    "        tools=[square_number],\n",
    "        think=\"high\"\n",
    "    )\n",
    "\n",
    "    print(final_response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8747972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function=Function(name='square_number', arguments={'number': 7612})\n"
     ]
    }
   ],
   "source": [
    "# Check what tool call was made\n",
    "print(response.message.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c248d5b",
   "metadata": {},
   "source": [
    "#### 2.4 Conclusion of Tool Calling  \n",
    "Using the model with one example tool completed successfully. Calling multiple tools would be a next step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
